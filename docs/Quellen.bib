
@misc{RL_Dota,
	doi = {10.48550/ARXIV.1912.06680},
	url = {https://arxiv.org/abs/1912.06680},
	author = {Christopher Berner and {et. al}},
	keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Dota 2 with Large Scale Deep Reinforcement Learning},
	publisher = {arXiv},
	year = {2019},
	copyright = {arXiv.org perpetual, non-exclusive license}
}
@inproceedings{RL_Atari,
	author = {Oh, Junhyuk and {et. al}},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Action-Conditional Video Prediction using Deep Networks in Atari Games},
	url = {https://proceedings.neurips.cc/paper/2015/file/6ba3af5d7b2790e73f0de32e5c8c1798-Paper.pdf},
	volume = {28},
	year = {2015}
}
@misc{RL_Starcraft,
	doi = {10.48550/ARXIV.1902.04043},
	url = {https://arxiv.org/abs/1902.04043},
	author = {Samvelyan, Mikayel and {et. al}},
	keywords = {Machine Learning (cs.LG), Multiagent Systems (cs.MA), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {The StarCraft Multi-Agent Challenge},
	publisher = {arXiv},
	year = {2019},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{unittest,
	title = {unittest â€” Unit testing framework},
	author = {Python Software Foundation},
	url = {https://docs.python.org/3/library/unittest.html},
	urldate = {17.11.2022},
}

@inproceedings{AC99,
	author = {Konda, Vijay and Tsitsiklis, John},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Solla and T. Leen and K. M\"{u}ller},
	publisher = {MIT Press},
	title = {Actor-Critic Algorithms},
	url = {https://proceedings.neurips.cc/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
	volume = {12},
	year = {1999}
}

@article{QLearning92,
	doi = {https://doi.org/10.1007/BF00992698},
	author = {Watkins, Christopher J. C. H. and  Dayan, Peter},
	keywords = {Q-learning, reinforcement learning, temporal differences, asynchornous dynamic programmning},
	title = {Q-Learning},
	journaltitle = {Machine Learning},
	year = {1992},
	volume = {8},
	pages = {279-292}
}

@book{SB20,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2020},
	publisher={MIT press},
	edition = {2},
	isbn = {9780262039246}
}
@article{AlphaGO,
	title={Mastering the game of Go with deep neural networks and tree search},
	author={Silver, David and and {et. al}},
	journal={nature},
	volume={529},
	number={7587},
	pages={484--489},
	year={2016},
	publisher={Nature Publishing Group}
}


@article{S16,
	title={Mastering the game of Go without
	human knowledge},
	author={Silver, David and and {et. al}},
  journal={nature},
volume={550},
number={7676},
pages={354--359},
year={2017},
publisher={Nature Publishing Group}
}


@article{KLM96,
	title={Reinforcement learning: A survey},
	author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
	journal={Journal of artificial intelligence research},
	volume={4},
	pages={237--285},
	year={1996}
}
